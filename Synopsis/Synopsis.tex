\documentclass[a4paper,12pt,table]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{fancyhdr}
\usepackage[table,xcdraw]{xcolor}
\usepackage{float}
\usepackage{blindtext}
\usepackage{microtype}
\usepackage[hidelinks]{hyperref}
\usepackage{graphicx}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{color,soul}


\renewcommand{\arraystretch}{2.5}

\setlength{\parindent}{0cm}
\setlength{\parskip}{1em}
\pagestyle{fancy}
\fancyhf{}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}
\rhead{
}
\fancyfoot[R]{\thepage}
\graphicspath{ {C:/Users/sarya/Desktop/Semester 4/ISM/Report} }

\begin{document}
    
\begin{titlepage}
    \begin{center} 
        \textbf{{\Huge Independent Study Module Synopsis}}
    \vspace{3cm}
    
    \end{center}
  \Large Reinforcement learning is a technique that has been successfully applied to various board games, such as Chess and Go. This paper will be exploring similar methods, such as value function approximation and Monte Carlo Tree Search, to optimize a similar board game, Santorini. By exploring these methods we have compared the efficacy of each method and have come up with an optimal agent which can play the game at a higher level than humans.  \par
 
        \vspace{0.5cm}
 
        \vspace{1.5cm}
 
 
        \vfill
 
 
        \begin{center}
            \textbf{Aryan Sarswat -  A0200521E \\
            Lim Wei Liang - A0205466E \\
            Roy Chua Dian Lun - A0199930N \\ }
    
           \vspace{0.8cm}
    
          University Scholars Programme\\
           National University of Singapore\\
        \end{center}
 \end{titlepage}
\end{document}